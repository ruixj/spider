#coding=utf-8
import sys
# import urllib
# import urllib2
# import cookielib
from helper.tools import *
from helper.parse_page import *
from lxml import etree
import json

# todo 尝试使用 scrapy

reload(sys)
sys.setdefaultencoding('utf8')
sys.setrecursionlimit(2000)

wp_url      = "http://www.microlele.com/dev/wp-json/wp/v2/posts"
wp_url_tags = "http://www.microlele.com/dev/wp-json/wp/v2/tags"
username    = "Admin"
password    = "Tjjtds@1"
 
ready_cate_id = "11"
wp_data = {}
wp_headers = {}
old_tags = {}

# todo 先获取所有的 old tags
res_old_tags = Crawl_helper_tools_url.http_auth_handle_get_tag(wp_url_tags,wp_data)
if (res_old_tags == "fail"):
    print('获取标签失败')
    sys.exit()
decode_res_tags = json.loads(res_old_tags)
for res_tag in decode_res_tags:
    old_tags[res_tag['name']] = res_tag['id']
print('已经存在的标签列表：')
print(old_tags)

posturl = 'http://news.sina.com.cn/china/xlxw/2017-05-14/doc-ifyfeius7910013.shtml'
root_url = 'http://blog.csdn.net'
# var = 'this is a var in'
# print(Crawl_helper_tools_url.testfunction(var))

headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0','Referer' : 'http:www.share345.com'}

crawl_url = Crawl_helper_tools_url(posturl,root_url)

html = crawl_url.getCurl(posturl,{},headers)
# print html
if html == '' or html == 'None':
    print '读取 html 失败'
    sys.exit()

print html
tree = etree.HTML(html)
 
 
try:

    page_content = "test";

    wp_data['status'] = "publish"
    wp_data['title'] = "test"
    wp_data['content'] = page_content
    wp_data['author'] = 1
    wp_data['slug'] = "test"
    wp_data['categories[0]'] = ready_cate_id

    #for tag_i in range(len(page_tags)):
     #   print(page_tags[tag_i])
      #  wp_data["tags["+str(tag_i)+"]"] = old_tags[page_tags[tag_i].decode('utf-8')]

 
    res = Crawl_helper_tools_url.http_auth(username,password,wp_url,wp_data,wp_headers)
    if (res == "fail"):
        print("添加失败")
    # sys.exit()

except Exception , e:
    print 'except 某篇文章出错....',e
 
